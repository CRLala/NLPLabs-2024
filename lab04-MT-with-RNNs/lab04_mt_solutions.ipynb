{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJMQLZ_uf6tI"
   },
   "source": [
    "# Lab 4: Machine Translation with Recurrent Neural Networks\n",
    "\n",
    "In this lab session, you will be improving your practical understanding of neural machine translation (NMT). For this, you will experiment with state-of-the-art recurrent neural machine translation (NMT) models. For training, you will be using the [Multi30k](https://github.com/multi30k/dataset) dataset, which contains around 30,000 image descriptions in English and their translations in German, French and Czech. Although Multi30k is often used for multimodal machine translation, it is a good candidate for quick MT experiments due to its smaller size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkbmDTO_SAUh"
   },
   "source": [
    "## 1. Downloading the corpus\n",
    "\n",
    "Let's start by downloading the corpus. We'll also install `sacreBLEU` for BLEU computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1eLd2J2B1i2u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sacrebleu==1.5.0 in /homes/cb221/.local/lib/python3.8/site-packages (1.5.0)\n",
      "Requirement already satisfied: portalocker in /homes/cb221/.local/lib/python3.8/site-packages (from sacrebleu==1.5.0) (2.7.0)\n",
      "\n",
      "Downloading train.lc.norm.tok.en\n",
      "Downloading train.lc.norm.tok.de\n",
      "Downloading train.lc.norm.tok.fr\n",
      "Downloading val.lc.norm.tok.en\n",
      "Downloading val.lc.norm.tok.de\n",
      "Downloading val.lc.norm.tok.fr\n",
      "Downloading test_2016_flickr.lc.norm.tok.en\n",
      "Downloading test_2016_flickr.lc.norm.tok.de\n",
      "Downloading test_2016_flickr.lc.norm.tok.fr\n",
      "\n",
      "     1\ttwo young , white males are outside near many bushes .\n",
      "     2\tseveral men in hard hats are operating a giant pulley system .\n",
      "     3\ta little girl climbing into a wooden playhouse .\n",
      "     4\ta man in a blue shirt is standing on a ladder cleaning a window .\n",
      "     5\ttwo men are at the stove preparing food .\n",
      "     6\ta man in green holds a guitar while the other man observes his shirt .\n",
      "     7\ta man is smiling at a stuffed lion\n",
      "     8\ta trendy girl talking on her cellphone while gliding slowly down the street .\n",
      "     9\ta woman with a large purse is walking by a gate .\n",
      "    10\tboys dancing on poles in the middle of the night .\n",
      "\n",
      "     1\tdeux jeunes hommes blancs sont dehors près de buissons .\n",
      "     2\tplusieurs hommes en casque font fonctionner un système de poulies géant .\n",
      "     3\tune petite fille grimpe dans une maisonnette en bois .\n",
      "     4\tun homme dans une chemise bleue se tient sur une échelle pour nettoyer une fenêtre .\n",
      "     5\tdeux hommes aux fourneaux préparent à manger .\n",
      "     6\tun homme en vert tient une guitare tandis qu&apos; un autre homme observe sa chemise .\n",
      "     7\tun homme sourit à un ours en peluche .\n",
      "     8\tune fille branchée parle à son portable tout en glissant lentement dans la rue .\n",
      "     9\tune femme avec un gros sac passe par une porte .\n",
      "    10\tdes garçons dansent sur des barres au milieu de la nuit .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# install sacreBLEU\n",
    "pip install sacrebleu==1.5.0\n",
    "echo\n",
    "\n",
    "# Download the corpus\n",
    "URL=\"https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/tok\"\n",
    "\n",
    "for split in \"train\" \"val\" \"test_2016_flickr\"; do\n",
    "  for lang in en de fr; do\n",
    "    fname=\"${split}.lc.norm.tok.${lang}\"\n",
    "    if [ ! -f $fname ]; then\n",
    "      echo \"Downloading $fname\"\n",
    "      wget -q \"${URL}/$fname\" -O \"${split/_2016_flickr/}.${lang}\"\n",
    "    fi\n",
    "  done\n",
    "done\n",
    "echo \n",
    "\n",
    "# Print the first 10 lines with line numbers of \n",
    "# the English and French training data\n",
    "cat -n train.en | head -n10\n",
    "echo\n",
    "\n",
    "cat -n train.fr | head -n10\n",
    "echo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzLYCAuD1-Ij"
   },
   "source": [
    "## 2. Setting up the environment\n",
    "\n",
    "The next step is to set up the environment for `pytorch` and define some helper functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GSFcmlFdf6tK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/cb221/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.13.1+cu117, CUDA: 11.7\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence, pack_sequence\n",
    "\n",
    "import sacrebleu\n",
    "\n",
    "###############\n",
    "# Torch setup #\n",
    "###############\n",
    "print('Torch version: {}, CUDA: {}'.format(torch.__version__, torch.version.cuda))\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "  print('WARNING: You may want to change the runtime to GPU for faster training!')\n",
    "  DEVICE = 'cpu'\n",
    "else:\n",
    "  DEVICE = 'cuda:0'\n",
    "\n",
    "#######################\n",
    "# Some helper functions\n",
    "#######################\n",
    "def fix_seed(seed=None):\n",
    "  \"\"\"Sets the seeds of random number generators.\"\"\"\n",
    "  if seed is None:\n",
    "    # Take a random seed\n",
    "    seed = time.time()\n",
    "  seed = int(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  return seed\n",
    "\n",
    "def readable_size(n):\n",
    "  \"\"\"Returns a readable size string for model parameters count.\"\"\"\n",
    "  sizes = ['K', 'M', 'G']\n",
    "  fmt = ''\n",
    "  size = n\n",
    "  for i, s in enumerate(sizes):\n",
    "    nn = n / (1000 ** (i + 1))\n",
    "    if nn >= 1:\n",
    "      size = nn\n",
    "      fmt = sizes[i]\n",
    "    else:\n",
    "      break\n",
    "  return '%.2f%s' % (size, fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWMhsDZOf6tS"
   },
   "source": [
    "## 3. Representing the vocabulary\n",
    "\n",
    "The `Vocabulary` class, which is defined below, encapsulates the **word-to-idx** and **idx-to-word** mapping that you should now be familiar with from the previous lab sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xlxMOBzPf6tT"
   },
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "  \"\"\"Data structure representing the vocabulary of a corpus.\"\"\"\n",
    "  def __init__(self):\n",
    "    # Mapping from tokens to integers\n",
    "    self._word2idx = {}\n",
    "\n",
    "    # Reverse-mapping from integers to tokens\n",
    "    self.idx2word = []\n",
    "\n",
    "    # 0-padding token\n",
    "    self.add_word('<pad>')\n",
    "    # sentence start\n",
    "    self.add_word('<s>')\n",
    "    # sentence end\n",
    "    self.add_word('</s>')\n",
    "    # Unknown words\n",
    "    self.add_word('<unk>')\n",
    "\n",
    "    self._pad_idx = self._word2idx['<pad>']\n",
    "    self._bos_idx = self._word2idx['<s>']\n",
    "    self._eos_idx = self._word2idx['</s>']\n",
    "    self._unk_idx = self._word2idx['<unk>']\n",
    "\n",
    "  def word2idx(self, word):\n",
    "    \"\"\"Returns the integer ID of the word or <unk> if not found.\"\"\"\n",
    "    return self._word2idx.get(word, self._unk_idx)\n",
    "\n",
    "  def add_word(self, word):\n",
    "    \"\"\"Adds the `word` into the vocabulary.\"\"\"\n",
    "    if word not in self._word2idx:\n",
    "      self.idx2word.append(word)\n",
    "      self._word2idx[word] = len(self.idx2word) - 1\n",
    "\n",
    "  def build_from_file(self, fname):\n",
    "    \"\"\"Builds a vocabulary from a given corpus file.\"\"\"\n",
    "    with open(fname) as f:\n",
    "      for line in f:\n",
    "        words = line.strip().split()\n",
    "        for word in words:\n",
    "          self.add_word(word)\n",
    "\n",
    "  def convert_idxs_to_words(self, idxs, until_eos=False):\n",
    "    \"\"\"Converts a list of indices to words.\"\"\"\n",
    "    if until_eos:\n",
    "      try:\n",
    "        idxs = idxs[:idxs.index(self.word2idx('</s>'))]\n",
    "      except ValueError:\n",
    "        pass\n",
    "\n",
    "    return ' '.join(self.idx2word[idx] for idx in idxs)\n",
    "\n",
    "  def convert_words_to_idxs(self, words, add_bos=False, add_eos=False):\n",
    "    \"\"\"Converts a list of words to a list of indices.\"\"\"\n",
    "    idxs = [self.word2idx(w) for w in words]\n",
    "    if add_bos:\n",
    "      idxs.insert(0, self.word2idx('<s>'))\n",
    "    if add_eos:\n",
    "      idxs.append(self.word2idx('</s>'))\n",
    "    return idxs\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"Returns the size of the vocabulary.\"\"\"\n",
    "    return len(self.idx2word)\n",
    "\n",
    "  def __repr__(self):\n",
    "    return \"Vocabulary with {} items\".format(self.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-4PQ9_8f6tV"
   },
   "source": [
    "## 4. Representing the corpus\n",
    "\n",
    "Below we define a `Multi30K` class that encapsulates the vocabularies and the source/target sides of train/dev/test splits. Two important methods are `read_sentences()` and `get_batches()` which you may want to read in detail. \n",
    "\n",
    "***Q1: Explain why `pad_sequence` is used in the `get_batches()` method***\n",
    "\n",
    "**A:** To construct a proper batch tensor, word indices should be padded to the length of the longest sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "e8GxcoBoETut"
   },
   "outputs": [],
   "source": [
    "class Multi30K:\n",
    "  \"\"\"A dataset wrapper for Multi30K.\"\"\"\n",
    "  def __init__(self, src_lang='en', trg_lang='fr'):\n",
    "    self.src_lang = src_lang\n",
    "    self.trg_lang = trg_lang\n",
    "\n",
    "    # Create vocabularies\n",
    "    self.src_vocab = Vocabulary()\n",
    "    self.src_vocab.build_from_file(f'train.{src_lang}')\n",
    "    self.trg_vocab = Vocabulary()\n",
    "    self.trg_vocab.build_from_file(f'train.{trg_lang}')\n",
    "\n",
    "    self.n_src_vocab = len(self.src_vocab)\n",
    "    self.n_trg_vocab = len(self.trg_vocab)\n",
    "\n",
    "    self._data = {}\n",
    "    for split in ('train', 'val', 'test'):\n",
    "      # Read sentences and map to indices using the vocabularies\n",
    "      print(f'Reading {split} set')\n",
    "      self._data[split] = self.read_sentences(split)\n",
    "\n",
    "  def read_sentences(self, split):\n",
    "    src_sents = []\n",
    "    trg_sents = []\n",
    "\n",
    "    # Read source side\n",
    "    with open(f'{split}.{self.src_lang}') as f:\n",
    "      for line in f:\n",
    "        line = line.strip()\n",
    "        assert line, \"Empty line found, please fix this!\"\n",
    "        idxs = self.src_vocab.convert_words_to_idxs(line.split(), add_eos=True)\n",
    "        src_sents.append(idxs)\n",
    "    # Read source side\n",
    "    with open(f'{split}.{self.trg_lang}') as f:\n",
    "      for line in f:\n",
    "        line = line.strip()\n",
    "        assert line, \"Empty line found, please fix this!\"\n",
    "        idxs = self.trg_vocab.convert_words_to_idxs(line.split(), add_bos=True, add_eos=True)\n",
    "        trg_sents.append(idxs)\n",
    "\n",
    "    assert len(src_sents) == len(trg_sents), \"Files are not aligned!\"\n",
    "    return src_sents, trg_sents\n",
    "\n",
    "  def get_batch(self, idxs, split='train'):\n",
    "    \"\"\"Returns padded torch tensors for source and target sample indices.\"\"\"\n",
    "    src_idxs = [torch.LongTensor(self._data[split][0][i]) for i in idxs]\n",
    "    trg_idxs = [torch.LongTensor(self._data[split][1][i]) for i in idxs]\n",
    "\n",
    "    ###################################\n",
    "    # Pad sequences to longest sequence\n",
    "    ###################################\n",
    "    padded_src_idxs = pad_sequence(src_idxs, padding_value=self.src_vocab._pad_idx)\n",
    "    padded_trg_idxs = pad_sequence(trg_idxs, padding_value=self.trg_vocab._pad_idx)\n",
    "    return padded_src_idxs.to(DEVICE), padded_trg_idxs.to(DEVICE)\n",
    "\n",
    "  def __repr__(self):\n",
    "    s = f\"Multi30K {self.src_lang} (# {self.n_src_vocab}) -> {self.trg_lang} (# {self.n_trg_vocab})\\n\"\n",
    "    s += f\" train: {len(self._data['train'][0])} sentences\\n\"\n",
    "    s += f\"   val: {len(self._data['val'][0])} sentences\\n\"\n",
    "    s += f\"  test: {len(self._data['test'][0])} sentences\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqXZCUkjgdp8"
   },
   "source": [
    "## 5. Create the dataset\n",
    "\n",
    "We now create a dataset instance to perform translation from French (FR) to English (EN). For demonstration purposes, we request a toy batch with 5 sentences and convert indices back to word forms.\n",
    "\n",
    "Notice how each column represents sentences and the shorter sequences are **zero-padded** at right.\n",
    "\n",
    "**NOTE**: Any code that deal with sequence-to-sequence paradigms should do its best to ignore these positions correctly, especially when using RNNs and Transformers with attention layers. Some support may come from the underlying toolkit that is used, through arguments related to **padding masks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "90mVETUYzN6B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train set\n",
      "Reading val set\n",
      "Reading test set\n",
      "Multi30K fr (# 11223) -> en (# 10214)\n",
      " train: 29000 sentences\n",
      "   val: 1014 sentences\n",
      "  test: 1000 sentences\n",
      "tensor([[   19,    19,    19,    89,    19],\n",
      "        [  133,   193,   181,     5,   193],\n",
      "        [   94,   181,   163,   157,   255],\n",
      "        [    6,   111,    94,     8,   163],\n",
      "        [10106,   201,    19,   201,    94],\n",
      "        [   92,   210,  1099,   268,    19],\n",
      "        [ 9295,    35,   183,    94,   688],\n",
      "        [   27,    71,   111,    19,    71],\n",
      "        [   19,   685,  1072,  1602,  7081],\n",
      "        [  719,     3,    43,   171,  2791],\n",
      "        [    2,    13,    19,    98,    23],\n",
      "        [    0,     2,   615,   127,  1999],\n",
      "        [    0,     0,    62,    13,    11],\n",
      "        [    0,     0,   522,     2,  2343],\n",
      "        [    0,     0,    15,     0,   457],\n",
      "        [    0,     0,   474,     0,    43],\n",
      "        [    0,     0,    13,     0,    23],\n",
      "        [    0,     0,     2,     0,   262],\n",
      "        [    0,     0,     0,     0,   338],\n",
      "        [    0,     0,     0,     0,  5921],\n",
      "        [    0,     0,     0,     0,    13],\n",
      "        [    0,     0,     0,     0,     2]], device='cuda:0')\n",
      "SRC:  un groupe d&apos; hommes chargent du coton dans un camion </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "TRG:  <s> a group of men are loading cotton onto a truck </s> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "SRC:  un jeune enfant est debout seul sur des rochers <unk> . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "TRG:  <s> a young child is standing alone on some jagged rocks . </s> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "SRC:  un enfant vêtu d&apos; un sweat-shirt rouge est accroché à un arbre la tête en bas . </s> <pad> <pad> <pad> <pad>\n",
      "TRG:  <s> a child wearing a red sweatshirt is hanging upside down from a tree . </s> <pad> <pad>\n",
      "\n",
      "SRC:  trois jeunes enfants sont debout autour d&apos; un baril bleu et blanc . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "TRG:  <s> three young children stand around a blue and white barrel . </s> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "SRC:  un jeune garçon vêtu d&apos; un maillot des giants brandit une batte de base-ball face à une balle qui arrive . </s>\n",
      "TRG:  <s> a young boy wearing a giants jersey swings a baseball bat at an incoming pitch . </s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = Multi30K(src_lang='fr', trg_lang='en')\n",
    "print(dataset)\n",
    "\n",
    "# Get a batch and see inside\n",
    "src_idxs, trg_idxs = dataset.get_batch([0, 10, 234, 12, 7], split='val')\n",
    "print(src_idxs)\n",
    "for i in range(src_idxs.shape[1]):\n",
    "  print('SRC: ', dataset.src_vocab.convert_idxs_to_words(src_idxs[:, i]))\n",
    "  print('TRG: ', dataset.trg_vocab.convert_idxs_to_words(trg_idxs[:, i]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmP0ZWbvB1aa"
   },
   "source": [
    "## 6. Encoder-Decoder Model\n",
    "\n",
    "In this section, you will implement an encoder-decoder model for neural machine translation (NMT). For a given source sentence $X = \\{x_1, \\dots, x_S\\}$ and the corresponding translation $Y = \\{y_1, \\dots, y_T\\}$, the model tries to predict the probability of words in the translation $Y$ using a **vectorial representation** $v$ of the source sentence.\n",
    "\n",
    "- The encoder is straight-forward: it receives the embeddings of the words in $X$ and produces contextualised representations for each position in the form of a matrix $H = \\{h_1, \\dots, h_S\\}$. The encoder can be uni- or bi-directional.\n",
    "\n",
    "- Several approaches exist to compress the whole source sentence into a single vector $v$:\n",
    "  - **Max pooling:** Perform a max pooling over $H$ to select the highest activations through time for each dimension.\n",
    "  - **Average pooling:** Take the average state as the representation by setting $v = \\frac{1}{S}\\sum_{i=1}^S h_i$.\n",
    "  - **Last hidden state:** Set $v = h_S$ assuming that the last hidden state of the RNN encoder would have collected as much linguistic information as possible from the source sentence.\n",
    "\n",
    "- The decoder is exactly a neural LM which is **additionally conditioned** over the representation vector $v$. The simplest way of achieving this is to set the  initial hidden state $d_0$ of the decoder to the (non-) linear projection of $v$.\n",
    "\n",
    "---\n",
    "\n",
    "**Q2: Follow the `EncDecNMT` class below and fill in the `<TODO>` items:**\n",
    "\n",
    "- **Line ~49:** Create the GRU encoder\n",
    "- **Line ~59:** Handle encoders' output dimension in bi-directional case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TZaoFR025lP3"
   },
   "outputs": [],
   "source": [
    "class EncDecNMT(nn.Module):\n",
    "  \"\"\"Encoder-decoder NMT without attention.\"\"\"\n",
    "  def __init__(self, dataset, emb_dim, enc_dim, dec_dim,\n",
    "               enc_bidirectional=False,\n",
    "               init_dec='max',\n",
    "               dropout=0.3, clip_gradient_norm=1.0, tie_weights=True,\n",
    "               batch_size=64):\n",
    "    # Call parent's __init__ first\n",
    "    super(EncDecNMT, self).__init__()\n",
    "\n",
    "    # Store arguments\n",
    "    self.dataset = dataset\n",
    "    self.emb_dim = emb_dim\n",
    "    self.enc_dim = enc_dim\n",
    "    self.enc_bidirectional = enc_bidirectional\n",
    "    self.dec_dim = dec_dim\n",
    "    self.init_dec = init_dec\n",
    "    self.clip_gradient_norm = clip_gradient_norm\n",
    "    self.p_dropout = dropout\n",
    "    self.tie_weights = tie_weights\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "    assert self.init_dec in ('max', 'avg'), \\\n",
    "      \"init_dec argument contains unknown value!\"\n",
    "\n",
    "    # Since target sequences are <pad>'ded, we want to ignore the loss\n",
    "    # values for those positions\n",
    "    self.loss = nn.CrossEntropyLoss(\n",
    "        reduction='none', ignore_index=self.dataset.trg_vocab._pad_idx)\n",
    "\n",
    "    # Create the dropout\n",
    "    self.drop = nn.Dropout(p=self.p_dropout)\n",
    "\n",
    "    ###############################################\n",
    "    # Create the source and target embedding layers\n",
    "    ###############################################\n",
    "    self.src_emb = nn.Embedding(\n",
    "      num_embeddings=self.dataset.n_src_vocab, embedding_dim=self.emb_dim,\n",
    "      padding_idx=self.dataset.src_vocab._pad_idx)\n",
    "    self.trg_emb = nn.Embedding(\n",
    "      num_embeddings=self.dataset.n_trg_vocab, embedding_dim=self.emb_dim,\n",
    "      padding_idx=self.dataset.trg_vocab._pad_idx)\n",
    "\n",
    "    ###########################################\n",
    "    # QUESTION\n",
    "    ###########################################\n",
    "    # Create the encoder by using the arguments\n",
    "    ###########################################\n",
    "    self.enc = nn.GRU(\n",
    "        input_size=self.emb_dim, hidden_size=self.enc_dim,\n",
    "        num_layers=1, bidirectional=self.enc_bidirectional,\n",
    "    )\n",
    "\n",
    "    ##################################################################\n",
    "    # QUESTION\n",
    "    ##################################################################\n",
    "    # Compute encoder's output dim which may be different than enc_dim\n",
    "    # because of bidirectionality\n",
    "    ##################################################################\n",
    "    self.enc_out_dim = self.enc_dim\n",
    "    if self.enc_bidirectional:\n",
    "      self.enc_out_dim *= 2\n",
    "\n",
    "    ###############################################################\n",
    "    # Let's use the `GRUCell` for decoder, which is designed to run for\n",
    "    # single timesteps through an explicit for loop. This will make\n",
    "    # it easier to understand the concepts shown at the lecture.\n",
    "    ###############################################################\n",
    "    self.dec = nn.GRUCell(input_size=self.emb_dim, hidden_size=self.dec_dim)\n",
    "\n",
    "    ##############################################################\n",
    "    # Add a non-linear layer for decoder initialisation projection\n",
    "    ##############################################################\n",
    "    self.ff_dec_init = nn.Sequential(\n",
    "        nn.Linear(self.enc_out_dim, self.dec_dim),\n",
    "        nn.Tanh(),\n",
    "    )\n",
    "\n",
    "    ####################################################################\n",
    "    # Bottleneck layer maps decoder's hidden state to emb size for tying\n",
    "    ####################################################################\n",
    "    self.bneck = nn.Linear(self.dec_dim, self.emb_dim)\n",
    "\n",
    "    ####################\n",
    "    # Final output layer\n",
    "    ####################\n",
    "    self.out = nn.Linear(self.emb_dim, self.dataset.n_trg_vocab)\n",
    "\n",
    "    ########################################################################\n",
    "    # This cuts the number of parameters by sharing the same embedding layer\n",
    "    # for both the inputs and outputs to/from the decoder GRU\n",
    "    ########################################################################\n",
    "    if self.tie_weights:\n",
    "      self.out.weight = self.trg_emb.weight\n",
    "\n",
    "    # Reset padding embeddings to all 0s for sanity\n",
    "    with torch.no_grad():\n",
    "        self.src_emb.weight.data[0].fill_(0)\n",
    "        self.trg_emb.weight.data[0].fill_(0)\n",
    "\n",
    "  def __repr__(self):\n",
    "    \"\"\"String representation for pretty-printing.\"\"\"\n",
    "    n_params = 0\n",
    "    for param in self.parameters():\n",
    "      n_params += np.cumprod(param.data.size())[-1]\n",
    "    n_params = readable_size(n_params)\n",
    "\n",
    "    s = super(EncDecNMT, self).__repr__()\n",
    "    return f\"{s}\\n# of parameters: {n_params} -- Decoder init: '{self.init_dec}'\"\n",
    "\n",
    "  def get_batch_indices(self, split='train', shuffle=True):\n",
    "    \"\"\"Returns the list of sample indices for a whole epoch.\"\"\"\n",
    "    # Get number of samples\n",
    "    n_samples = len(self.dataset._data[split][0])\n",
    "\n",
    "    # Get sample indices and batch them\n",
    "    if shuffle:\n",
    "      order = torch.randperm(n_samples)\n",
    "    else:\n",
    "      order = torch.arange(n_samples)\n",
    "\n",
    "    start_offsets = range(0, n_samples, self.batch_size)\n",
    "    return [order[i: i + self.batch_size] for i in start_offsets]\n",
    "\n",
    "  ###################################\n",
    "  # Decoder initialisation approaches\n",
    "  ###################################\n",
    "  def get_encoder_max_state(self, enc_states, input_mask):\n",
    "    \"\"\"Computes h_0 for the decoder based on the max-pooled encoding state.\"\"\"\n",
    "    # we fill the padded position values with small numbers so that\n",
    "    # max-pooling is not able to return wrong max values\n",
    "    masked_states = enc_states.masked_fill(\n",
    "        input_mask.unsqueeze(-1).bool().logical_not(), -100000)\n",
    "    max_state = masked_states.max(0)[0]\n",
    "    return max_state\n",
    "\n",
    "  def get_encoder_avg_state(self, enc_states, input_mask):\n",
    "    \"\"\"Computes the average of encoder states taking care of padding.\"\"\"\n",
    "    ##############################################################\n",
    "    # QUESTION\n",
    "    ##############################################################\n",
    "    # Compute the average encoder states by taking into account\n",
    "    # sentence length information through `input_mask`\n",
    "    ##############################################################\n",
    "    # raise RuntimeError('Not implemented yet!')\n",
    "    return enc_states.sum(0).div(input_mask.sum(0).unsqueeze(-1))\n",
    "\n",
    "  def compute_decoder_state(self, enc_states, input_mask):\n",
    "    \"\"\"Calls the appropriate `init_dec` method, projects the `v`.\"\"\"\n",
    "    func = getattr(self, f'get_encoder_{self.init_dec}_state')\n",
    "    # Get the vector `v`\n",
    "    h_0 = func(enc_states, input_mask)\n",
    "    # Project it with the FF\n",
    "    return self.ff_dec_init(h_0)\n",
    "\n",
    "  ####################################\n",
    "  # Encodes a batch of input sentences\n",
    "  ####################################\n",
    "  def encode(self, x):\n",
    "    \"\"\"Encode tokens `x` to obtain the encoder states.\"\"\"\n",
    "    # Compute the mask to detect <pad>'s in the further parts\n",
    "    # x is a padded tensor of shape (seq_len, batch_size)\n",
    "    # mask: (seq_len, batch_size)\n",
    "    self.mask = x.ne(self.dataset.src_vocab._pad_idx).long()\n",
    "\n",
    "    # src_embs: (seq_len, batch_size, emb_dim)\n",
    "    embs = self.drop(self.src_emb(x))\n",
    "\n",
    "    # Pack the tensor so that RNN correctly computes the hidden\n",
    "    # states by ignoring padded positions\n",
    "    packed_inputs = pack_padded_sequence(\n",
    "        embs, lengths=self.mask.sum(0).long().cpu(), enforce_sorted=False)\n",
    "\n",
    "    # Encode -> unpack to obtain an ordinary tensor of hidden states\n",
    "    # padded positions will now have explicit 0's in their hidden states\n",
    "    # all_hids: (seq_len, batch_size, self.enc_out_dim)\n",
    "    self.all_hids = pad_packed_sequence(self.enc(packed_inputs)[0])[0]\n",
    "    return self.all_hids, self.mask\n",
    "\n",
    "  def compute_loss_from_logits(self, logits, y):\n",
    "    \"\"\"Returns the scalar losses for every element in the batch.\"\"\"\n",
    "    return self.loss(logits, y)\n",
    "\n",
    "  def compute_decoder_logits(self, dec_hid_state, y):\n",
    "    # *Cell() functions return (batch_size, hidden_size) i.e.\n",
    "    # a tensor containing the computed hidden state for each element in the batch\n",
    "    dec_hid_state = self.dec(self.trg_emb(y), dec_hid_state)\n",
    "    logits = self.out(self.bneck(self.drop(dec_hid_state)))\n",
    "    return logits, dec_hid_state\n",
    "\n",
    "  def forward(self, x, y):\n",
    "    \"\"\"Forward-pass of the model for training/ppl evaluation only.\"\"\"\n",
    "    # Encode source sentence and get encoder states\n",
    "    enc_states, input_mask = self.encode(x)\n",
    "\n",
    "    # Compute decoder's initial state h_0 for each sentence\n",
    "    dec_hid_state = self.compute_decoder_state(enc_states, input_mask)\n",
    "\n",
    "    # Manually compute the loss for each decoding timestep\n",
    "    # We skip the last item since we don't want to input </s>\n",
    "    loss = 0.0\n",
    "    n_trg_tokens = 0\n",
    "    for t in range(y.size(0) - 1):\n",
    "      y_prev, y_next = y[t], y[t + 1]\n",
    "\n",
    "      # Do a recurrence step\n",
    "      logits, dec_hid_state = self.compute_decoder_logits(dec_hid_state, y_prev)\n",
    "\n",
    "      # Accumulate the sequence loss\n",
    "      loss += self.compute_loss_from_logits(logits, y_next).sum()\n",
    "\n",
    "      # Compute number of valid positions by ignoring <pad>'s\n",
    "      n_trg_tokens += y_next.ne(self.dataset.trg_vocab._pad_idx).sum()\n",
    "\n",
    "    return loss, float(n_trg_tokens.item())\n",
    "\n",
    "  def train_model(self, optim, n_epochs=5):\n",
    "    \"\"\"Trains the model.\"\"\"\n",
    "    train_ppls, val_ppls = [], []\n",
    "\n",
    "    for eidx in range(1, n_epochs + 1):\n",
    "      start_time = time.time()\n",
    "      epoch_loss = 0\n",
    "      epoch_items = 0\n",
    "\n",
    "      # Enable training mode\n",
    "      self.train()\n",
    "\n",
    "      # Start training (will shuffle at each epoch)\n",
    "      for iter_count, idxs in enumerate(self.get_batch_indices('train')):\n",
    "        # Get x's and y's\n",
    "        x, y = self.dataset.get_batch(idxs)\n",
    "\n",
    "        # Clear the gradients\n",
    "        optim.zero_grad()\n",
    "\n",
    "        total_loss, n_items = self.forward(x, y)\n",
    "\n",
    "        # Backprop the average loss and update parameters\n",
    "        total_loss.div(n_items).backward()\n",
    "\n",
    "        # Clip the gradients to avoid exploding gradients\n",
    "        if self.clip_gradient_norm > 0:\n",
    "          torch.nn.utils.clip_grad_norm_(self.parameters(), self.clip_gradient_norm)\n",
    "\n",
    "        # Update parameters\n",
    "        optim.step()\n",
    "\n",
    "        # sum the loss for reporting, along with the denominator\n",
    "        epoch_loss += total_loss.item()\n",
    "        epoch_items += n_items\n",
    "\n",
    "        # Overall epoch loss and ppl\n",
    "        loss_per_token = epoch_loss / epoch_items\n",
    "        ppl = math.exp(loss_per_token)\n",
    "\n",
    "        if (iter_count + 1) % 100 == 0:\n",
    "          # Print progress\n",
    "          print(f'[Epoch {eidx:<3}] loss: {loss_per_token:6.2f}, perplexity: {ppl:6.2f}')\n",
    "\n",
    "      time_spent = time.time() - start_time\n",
    "\n",
    "      print(f'[Epoch {eidx:<3}] ended with train_loss: {loss_per_token:6.2f}, train_ppl: {ppl:6.2f}')\n",
    "      train_ppls.append(ppl)\n",
    "\n",
    "      # Evaluate on valid set\n",
    "      valid_loss, valid_ppl = self.evaluate('val')\n",
    "      val_ppls.append(valid_ppl)\n",
    "      print(f'[Epoch {eidx:<3}] ended with valid_loss: {valid_loss:6.2f}, valid_ppl: {valid_ppl:6.2f}')\n",
    "      print(f'[Epoch {eidx:<3}] completed in {time_spent:.2f} seconds')\n",
    "      print(f'[Epoch {eidx:<3}] validation BLEU with greedy search:')\n",
    "\n",
    "      bleu = self.greedy_search('val')\n",
    "      print(f'[Epoch {eidx:<3}] {bleu}\\n')\n",
    "\n",
    "    ######################################\n",
    "    # Evaluate the final model on test set\n",
    "    ######################################\n",
    "    test_loss, test_ppl = self.evaluate('test')\n",
    "    print(f' ---> Final test set performance: {test_loss:6.2f}, test_ppl: {test_ppl:6.2f}')\n",
    "\n",
    "  def evaluate(self, split):\n",
    "    # Switch to eval mode\n",
    "    self.eval()\n",
    "\n",
    "    eval_loss = 0.\n",
    "    eval_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for iter_count, idxs in enumerate(self.get_batch_indices(split, shuffle=False)):\n",
    "        # Get x's and y's\n",
    "        x, y = self.dataset.get_batch(idxs, split=split)\n",
    "\n",
    "        total_loss, n_items = self.forward(x, y)\n",
    "        eval_loss += total_loss.item()\n",
    "        eval_tokens += n_items\n",
    "    eval_loss /= eval_tokens\n",
    "\n",
    "    return eval_loss, math.exp(eval_loss)\n",
    "\n",
    "  def greedy_search(self, split, max_len=60):\n",
    "    \"\"\"Performs a greedy search, dumps the translations and computes BLEU.\"\"\"\n",
    "    # Switch to eval mode\n",
    "    self.eval()\n",
    "\n",
    "    bos = self.dataset.trg_vocab._bos_idx\n",
    "    eos = self.dataset.trg_vocab._eos_idx\n",
    "\n",
    "    # We keep the hypotheses for a batch in a tensor for efficiency\n",
    "    # Although there's a hard-limit for decoding timesteps `max_len`,\n",
    "    # the hypotheses will likely to produce </s> before reaching `max_len`.\n",
    "    batch_hyps = torch.zeros(\n",
    "      (max_len, self.batch_size), dtype=torch.long,\n",
    "      device=self.trg_emb.weight.device)\n",
    "\n",
    "    # Resulting sentences in dataset split order\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for iter_count, idxs in enumerate(self.get_batch_indices(split, shuffle=False)):\n",
    "        # We don't care about `y` for translation decoding\n",
    "        # i.e. we rely on model's own predictions rather than ground-truths\n",
    "        x, _ = self.dataset.get_batch(idxs, split=split)\n",
    "\n",
    "        # Clear batch hypotheses tensor\n",
    "        batch_hyps.zero_()\n",
    "\n",
    "        # Get encoder hidden states\n",
    "        enc_states, input_mask = self.encode(x)\n",
    "\n",
    "        # Compute decoder's initial state h_0 for each sentence\n",
    "        h = self.compute_decoder_state(enc_states, input_mask)\n",
    "\n",
    "        # last batch could be smaller than the requested batch size\n",
    "        cur_batch_size = h.size(0)\n",
    "\n",
    "        # Start all sentences with <s>\n",
    "        next_word_idxs = torch.full(\n",
    "            (cur_batch_size, ), bos, dtype=torch.long, device=h.device)\n",
    "\n",
    "        # Track sentences who already produced </s>\n",
    "        track_fini = torch.zeros((cur_batch_size, ), device=h.device).bool()\n",
    "\n",
    "        # A maximum of `max_len` decoding steps\n",
    "        for t in range(max_len):\n",
    "          if track_fini.all():\n",
    "            # All hypotheses produced </s>, early stop!\n",
    "            break\n",
    "\n",
    "          # Get logits from the decoder\n",
    "          logits, h = self.compute_decoder_logits(h, next_word_idxs)\n",
    "\n",
    "          # Get next probabilities and argmax them for every sentence\n",
    "          next_word_idxs = nn.functional.softmax(logits, dim=-1).argmax(dim=-1)\n",
    "\n",
    "          # Update finished sentence tracker\n",
    "          track_fini.add_(next_word_idxs.eq(eos))\n",
    "\n",
    "          # Insert most probable words for timestep `t` into tensor\n",
    "          batch_hyps[t, :cur_batch_size] = next_word_idxs\n",
    "\n",
    "        # All finished, convert translations to python lists on CPU\n",
    "        results.extend(batch_hyps[:, :cur_batch_size].t().cpu().tolist())\n",
    "\n",
    "    # post-process results to convert them to actual sentences\n",
    "    out_fname = f'{split}_translations.{self.dataset.trg_lang}'\n",
    "    ref_fname = f'{split}.{self.dataset.trg_lang}'\n",
    "    hyps = []\n",
    "    refs = []\n",
    "\n",
    "    # read references\n",
    "    with open(ref_fname) as f:\n",
    "      for line in f:\n",
    "        refs.append(line.strip())\n",
    "\n",
    "    # Write hyps\n",
    "    with open(out_fname, 'w') as f:\n",
    "      for sent in results:\n",
    "        sent_str = self.dataset.trg_vocab.convert_idxs_to_words(sent, True)\n",
    "        hyps.append(sent_str)\n",
    "        f.write(sent_str + '\\n')\n",
    "\n",
    "    # Compute BLEU\n",
    "    bleu = sacrebleu.corpus_bleu(hyps, [refs], tokenize='none')\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0eHpYiRUHDe"
   },
   "source": [
    "## 7. Training the model\n",
    "\n",
    "The following function trains an encoder-decoder NMT with the base hyper-parameters that you can override through the keyword arguments. Proceed to the next code block for the actual training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3kzOvvY6f6tx"
   },
   "outputs": [],
   "source": [
    "def train_encdec_model(n_epochs=5, init_lr=0.0005, **kwargs):\n",
    "  # Set the seed for reproducible results\n",
    "  fix_seed(30494)\n",
    "\n",
    "  base_params = {\n",
    "    'dataset':dataset,\n",
    "    'emb_dim':200,              # word embedding dim\n",
    "    'enc_dim':200,              # hidden layer dim for the encoder\n",
    "    'enc_bidirectional':False,  # True makes the encoder bidirectional\n",
    "    'dec_dim':300,              # hidden layer dim for the decoder\n",
    "    'clip_gradient_norm':1.0,   # gradient clip threshold\n",
    "    'dropout':0.3,              # dropout probability\n",
    "    'tie_weights':True,         # Weight typing for decoder inputs/outputs\n",
    "    'batch_size':64,            # Batch size\n",
    "    'init_dec':'max',          # Initialize the decoder with max or avg state\n",
    "  }\n",
    "\n",
    "  # Override with given arguments\n",
    "  base_params.update(kwargs)\n",
    "\n",
    "  # Create the Pytorch model\n",
    "  model = EncDecNMT(**base_params)\n",
    "\n",
    "  # move to device\n",
    "  model.to(DEVICE)\n",
    "\n",
    "  # Create the optimizer\n",
    "  opt = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "  print(model)\n",
    "\n",
    "  # Returns train, val and test perplexities\n",
    "  model.train_model(opt, n_epochs=n_epochs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIJ1vPygDI3h"
   },
   "source": [
    "Below, you can add different configurations to `param_set` and they will be trained sequentially. At the end, the final model parameters will be used to decode the translations for the test set and BLEU scores will be computed and printed for each configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "j9VPp4wqkknL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************\n",
      "Training {'enc_bidirectional': False, 'init_dec': 'max'}\n",
      "********************************************************\n",
      "EncDecNMT(\n",
      "  (loss): CrossEntropyLoss()\n",
      "  (drop): Dropout(p=0.3, inplace=False)\n",
      "  (src_emb): Embedding(11223, 200, padding_idx=0)\n",
      "  (trg_emb): Embedding(10214, 200, padding_idx=0)\n",
      "  (enc): GRU(200, 200)\n",
      "  (dec): GRUCell(200, 300)\n",
      "  (ff_dec_init): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=300, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (bneck): Linear(in_features=300, out_features=200, bias=True)\n",
      "  (out): Linear(in_features=200, out_features=10214, bias=True)\n",
      ")\n",
      "# of parameters: 5.11M -- Decoder init: 'max'\n",
      "[Epoch 1  ] loss:   6.72, perplexity: 826.55\n",
      "[Epoch 1  ] loss:   5.91, perplexity: 369.87\n",
      "[Epoch 1  ] loss:   5.46, perplexity: 235.96\n",
      "[Epoch 1  ] loss:   5.17, perplexity: 175.43\n",
      "[Epoch 1  ] ended with train_loss:   5.04, train_ppl: 155.13\n",
      "[Epoch 1  ] ended with valid_loss:   3.85, valid_ppl:  46.98\n",
      "[Epoch 1  ] completed in 17.72 seconds\n",
      "[Epoch 1  ] validation BLEU with greedy search:\n",
      "[Epoch 1  ] BLEU = 11.41 47.5/17.6/8.1/3.7 (BP = 0.907 ratio = 0.911 hyp_len = 12122 ref_len = 13308)\n",
      "\n",
      "[Epoch 2  ] loss:   3.88, perplexity:  48.20\n",
      "[Epoch 2  ] loss:   3.83, perplexity:  46.21\n",
      "[Epoch 2  ] loss:   3.80, perplexity:  44.52\n",
      "[Epoch 2  ] loss:   3.76, perplexity:  42.96\n",
      "[Epoch 2  ] ended with train_loss:   3.74, train_ppl:  42.14\n",
      "[Epoch 2  ] ended with valid_loss:   3.44, valid_ppl:  31.32\n",
      "[Epoch 2  ] completed in 17.68 seconds\n",
      "[Epoch 2  ] validation BLEU with greedy search:\n",
      "[Epoch 2  ] BLEU = 14.81 49.2/19.9/10.0/5.1 (BP = 0.989 ratio = 0.989 hyp_len = 13165 ref_len = 13308)\n",
      "\n",
      "[Epoch 3  ] loss:   3.46, perplexity:  31.73\n",
      "[Epoch 3  ] loss:   3.43, perplexity:  30.99\n",
      "[Epoch 3  ] loss:   3.42, perplexity:  30.59\n",
      "[Epoch 3  ] loss:   3.41, perplexity:  30.21\n",
      "[Epoch 3  ] ended with train_loss:   3.40, train_ppl:  29.98\n",
      "[Epoch 3  ] ended with valid_loss:   3.22, valid_ppl:  25.00\n",
      "[Epoch 3  ] completed in 17.80 seconds\n",
      "[Epoch 3  ] validation BLEU with greedy search:\n",
      "[Epoch 3  ] BLEU = 16.19 49.1/21.3/11.0/6.0 (BP = 1.000 ratio = 1.052 hyp_len = 14006 ref_len = 13308)\n",
      "\n",
      "[Epoch 4  ] loss:   3.23, perplexity:  25.40\n",
      "[Epoch 4  ] loss:   3.22, perplexity:  25.08\n",
      "[Epoch 4  ] loss:   3.21, perplexity:  24.72\n",
      "[Epoch 4  ] loss:   3.19, perplexity:  24.33\n",
      "[Epoch 4  ] ended with train_loss:   3.19, train_ppl:  24.27\n",
      "[Epoch 4  ] ended with valid_loss:   3.09, valid_ppl:  21.95\n",
      "[Epoch 4  ] completed in 17.65 seconds\n",
      "[Epoch 4  ] validation BLEU with greedy search:\n",
      "[Epoch 4  ] BLEU = 18.04 53.1/23.6/12.6/6.9 (BP = 0.991 ratio = 0.991 hyp_len = 13187 ref_len = 13308)\n",
      "\n",
      "[Epoch 5  ] loss:   3.04, perplexity:  20.92\n",
      "[Epoch 5  ] loss:   3.06, perplexity:  21.32\n",
      "[Epoch 5  ] loss:   3.04, perplexity:  20.97\n",
      "[Epoch 5  ] loss:   3.04, perplexity:  20.92\n",
      "[Epoch 5  ] ended with train_loss:   3.03, train_ppl:  20.76\n",
      "[Epoch 5  ] ended with valid_loss:   2.97, valid_ppl:  19.41\n",
      "[Epoch 5  ] completed in 17.53 seconds\n",
      "[Epoch 5  ] validation BLEU with greedy search:\n",
      "[Epoch 5  ] BLEU = 19.32 53.5/24.6/13.5/7.8 (BP = 1.000 ratio = 1.022 hyp_len = 13607 ref_len = 13308)\n",
      "\n",
      " ---> Final test set performance:   2.92, test_ppl:  18.52\n",
      "********************************************************\n",
      "Training {'enc_bidirectional': False, 'init_dec': 'avg'}\n",
      "********************************************************\n",
      "EncDecNMT(\n",
      "  (loss): CrossEntropyLoss()\n",
      "  (drop): Dropout(p=0.3, inplace=False)\n",
      "  (src_emb): Embedding(11223, 200, padding_idx=0)\n",
      "  (trg_emb): Embedding(10214, 200, padding_idx=0)\n",
      "  (enc): GRU(200, 200)\n",
      "  (dec): GRUCell(200, 300)\n",
      "  (ff_dec_init): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=300, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (bneck): Linear(in_features=300, out_features=200, bias=True)\n",
      "  (out): Linear(in_features=200, out_features=10214, bias=True)\n",
      ")\n",
      "# of parameters: 5.11M -- Decoder init: 'avg'\n",
      "[Epoch 1  ] loss:   6.68, perplexity: 795.52\n",
      "[Epoch 1  ] loss:   5.89, perplexity: 362.78\n",
      "[Epoch 1  ] loss:   5.45, perplexity: 233.80\n",
      "[Epoch 1  ] loss:   5.16, perplexity: 174.43\n",
      "[Epoch 1  ] ended with train_loss:   5.04, train_ppl: 154.38\n",
      "[Epoch 1  ] ended with valid_loss:   3.85, valid_ppl:  47.15\n",
      "[Epoch 1  ] completed in 17.34 seconds\n",
      "[Epoch 1  ] validation BLEU with greedy search:\n",
      "[Epoch 1  ] BLEU = 11.01 47.8/17.3/7.6/3.3 (BP = 0.915 ratio = 0.918 hyp_len = 12221 ref_len = 13308)\n",
      "\n",
      "[Epoch 2  ] loss:   3.87, perplexity:  48.18\n",
      "[Epoch 2  ] loss:   3.83, perplexity:  46.10\n",
      "[Epoch 2  ] loss:   3.79, perplexity:  44.36\n",
      "[Epoch 2  ] loss:   3.76, perplexity:  42.79\n",
      "[Epoch 2  ] ended with train_loss:   3.74, train_ppl:  41.98\n",
      "[Epoch 2  ] ended with valid_loss:   3.43, valid_ppl:  30.92\n",
      "[Epoch 2  ] completed in 17.21 seconds\n",
      "[Epoch 2  ] validation BLEU with greedy search:\n",
      "[Epoch 2  ] BLEU = 14.31 49.4/19.4/9.5/4.8 (BP = 0.990 ratio = 0.990 hyp_len = 13173 ref_len = 13308)\n",
      "\n",
      "[Epoch 3  ] loss:   3.45, perplexity:  31.60\n",
      "[Epoch 3  ] loss:   3.43, perplexity:  30.85\n",
      "[Epoch 3  ] loss:   3.42, perplexity:  30.43\n",
      "[Epoch 3  ] loss:   3.40, perplexity:  30.06\n",
      "[Epoch 3  ] ended with train_loss:   3.40, train_ppl:  29.83\n",
      "[Epoch 3  ] ended with valid_loss:   3.21, valid_ppl:  24.70\n",
      "[Epoch 3  ] completed in 17.83 seconds\n",
      "[Epoch 3  ] validation BLEU with greedy search:\n",
      "[Epoch 3  ] BLEU = 15.98 48.8/20.8/10.8/5.9 (BP = 1.000 ratio = 1.068 hyp_len = 14217 ref_len = 13308)\n",
      "\n",
      "[Epoch 4  ] loss:   3.23, perplexity:  25.18\n",
      "[Epoch 4  ] loss:   3.21, perplexity:  24.90\n",
      "[Epoch 4  ] loss:   3.20, perplexity:  24.52\n",
      "[Epoch 4  ] loss:   3.18, perplexity:  24.11\n",
      "[Epoch 4  ] ended with train_loss:   3.18, train_ppl:  24.03\n",
      "[Epoch 4  ] ended with valid_loss:   3.07, valid_ppl:  21.61\n",
      "[Epoch 4  ] completed in 18.14 seconds\n",
      "[Epoch 4  ] validation BLEU with greedy search:\n",
      "[Epoch 4  ] BLEU = 17.83 53.2/23.8/12.5/6.9 (BP = 0.980 ratio = 0.980 hyp_len = 13045 ref_len = 13308)\n",
      "\n",
      "[Epoch 5  ] loss:   3.03, perplexity:  20.65\n",
      "[Epoch 5  ] loss:   3.04, perplexity:  20.97\n",
      "[Epoch 5  ] loss:   3.03, perplexity:  20.63\n",
      "[Epoch 5  ] loss:   3.02, perplexity:  20.58\n",
      "[Epoch 5  ] ended with train_loss:   3.02, train_ppl:  20.42\n",
      "[Epoch 5  ] ended with valid_loss:   2.94, valid_ppl:  18.99\n",
      "[Epoch 5  ] completed in 18.60 seconds\n",
      "[Epoch 5  ] validation BLEU with greedy search:\n",
      "[Epoch 5  ] BLEU = 19.15 52.7/24.6/13.4/7.8 (BP = 1.000 ratio = 1.040 hyp_len = 13835 ref_len = 13308)\n",
      "\n",
      " ---> Final test set performance:   2.89, test_ppl:  18.05\n",
      "*******************************************************\n",
      "Training {'enc_bidirectional': True, 'init_dec': 'max'}\n",
      "*******************************************************\n",
      "EncDecNMT(\n",
      "  (loss): CrossEntropyLoss()\n",
      "  (drop): Dropout(p=0.3, inplace=False)\n",
      "  (src_emb): Embedding(11223, 200, padding_idx=0)\n",
      "  (trg_emb): Embedding(10214, 200, padding_idx=0)\n",
      "  (enc): GRU(200, 200, bidirectional=True)\n",
      "  (dec): GRUCell(200, 300)\n",
      "  (ff_dec_init): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=300, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (bneck): Linear(in_features=300, out_features=200, bias=True)\n",
      "  (out): Linear(in_features=200, out_features=10214, bias=True)\n",
      ")\n",
      "# of parameters: 5.41M -- Decoder init: 'max'\n",
      "[Epoch 1  ] loss:   6.72, perplexity: 829.59\n",
      "[Epoch 1  ] loss:   5.92, perplexity: 371.02\n",
      "[Epoch 1  ] loss:   5.46, perplexity: 235.28\n",
      "[Epoch 1  ] loss:   5.15, perplexity: 171.91\n",
      "[Epoch 1  ] ended with train_loss:   5.02, train_ppl: 151.82\n",
      "[Epoch 1  ] ended with valid_loss:   3.87, valid_ppl:  47.76\n",
      "[Epoch 1  ] completed in 18.71 seconds\n",
      "[Epoch 1  ] validation BLEU with greedy search:\n",
      "[Epoch 1  ] BLEU = 11.47 55.1/21.3/10.5/5.0 (BP = 0.729 ratio = 0.760 hyp_len = 10109 ref_len = 13308)\n",
      "\n",
      "[Epoch 2  ] loss:   3.86, perplexity:  47.31\n",
      "[Epoch 2  ] loss:   3.82, perplexity:  45.60\n",
      "[Epoch 2  ] loss:   3.76, perplexity:  43.04\n",
      "[Epoch 2  ] loss:   3.71, perplexity:  41.05\n",
      "[Epoch 2  ] ended with train_loss:   3.70, train_ppl:  40.26\n",
      "[Epoch 2  ] ended with valid_loss:   3.41, valid_ppl:  30.15\n",
      "[Epoch 2  ] completed in 18.45 seconds\n",
      "[Epoch 2  ] validation BLEU with greedy search:\n",
      "[Epoch 2  ] BLEU = 15.77 55.8/24.1/12.5/6.7 (BP = 0.859 ratio = 0.868 hyp_len = 11557 ref_len = 13308)\n",
      "\n",
      "[Epoch 3  ] loss:   3.39, perplexity:  29.62\n",
      "[Epoch 3  ] loss:   3.38, perplexity:  29.30\n",
      "[Epoch 3  ] loss:   3.36, perplexity:  28.82\n",
      "[Epoch 3  ] loss:   3.34, perplexity:  28.32\n",
      "[Epoch 3  ] ended with train_loss:   3.33, train_ppl:  28.05\n",
      "[Epoch 3  ] ended with valid_loss:   3.19, valid_ppl:  24.21\n",
      "[Epoch 3  ] completed in 18.28 seconds\n",
      "[Epoch 3  ] validation BLEU with greedy search:\n",
      "[Epoch 3  ] BLEU = 17.85 57.3/25.9/13.7/7.7 (BP = 0.898 ratio = 0.902 hyp_len = 12010 ref_len = 13308)\n",
      "\n",
      "[Epoch 4  ] loss:   3.15, perplexity:  23.30\n",
      "[Epoch 4  ] loss:   3.13, perplexity:  22.91\n",
      "[Epoch 4  ] loss:   3.13, perplexity:  22.86\n",
      "[Epoch 4  ] loss:   3.12, perplexity:  22.58\n",
      "[Epoch 4  ] ended with train_loss:   3.11, train_ppl:  22.39\n",
      "[Epoch 4  ] ended with valid_loss:   3.02, valid_ppl:  20.44\n",
      "[Epoch 4  ] completed in 18.23 seconds\n",
      "[Epoch 4  ] validation BLEU with greedy search:\n",
      "[Epoch 4  ] BLEU = 19.91 56.9/26.8/14.7/8.5 (BP = 0.953 ratio = 0.954 hyp_len = 12696 ref_len = 13308)\n",
      "\n",
      "[Epoch 5  ] loss:   2.95, perplexity:  19.12\n",
      "[Epoch 5  ] loss:   2.94, perplexity:  18.95\n",
      "[Epoch 5  ] loss:   2.95, perplexity:  19.02\n",
      "[Epoch 5  ] loss:   2.94, perplexity:  19.00\n",
      "[Epoch 5  ] ended with train_loss:   2.94, train_ppl:  18.89\n",
      "[Epoch 5  ] ended with valid_loss:   2.95, valid_ppl:  19.10\n",
      "[Epoch 5  ] completed in 18.54 seconds\n",
      "[Epoch 5  ] validation BLEU with greedy search:\n",
      "[Epoch 5  ] BLEU = 20.62 61.3/29.9/16.4/9.7 (BP = 0.888 ratio = 0.894 hyp_len = 11894 ref_len = 13308)\n",
      "\n",
      " ---> Final test set performance:   2.88, test_ppl:  17.85\n",
      "*******************************************************\n",
      "Training {'enc_bidirectional': True, 'init_dec': 'avg'}\n",
      "*******************************************************\n",
      "EncDecNMT(\n",
      "  (loss): CrossEntropyLoss()\n",
      "  (drop): Dropout(p=0.3, inplace=False)\n",
      "  (src_emb): Embedding(11223, 200, padding_idx=0)\n",
      "  (trg_emb): Embedding(10214, 200, padding_idx=0)\n",
      "  (enc): GRU(200, 200, bidirectional=True)\n",
      "  (dec): GRUCell(200, 300)\n",
      "  (ff_dec_init): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=300, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (bneck): Linear(in_features=300, out_features=200, bias=True)\n",
      "  (out): Linear(in_features=200, out_features=10214, bias=True)\n",
      ")\n",
      "# of parameters: 5.41M -- Decoder init: 'avg'\n",
      "[Epoch 1  ] loss:   6.68, perplexity: 798.89\n",
      "[Epoch 1  ] loss:   5.90, perplexity: 365.24\n",
      "[Epoch 1  ] loss:   5.46, perplexity: 234.18\n",
      "[Epoch 1  ] loss:   5.15, perplexity: 171.60\n",
      "[Epoch 1  ] ended with train_loss:   5.02, train_ppl: 151.66\n",
      "[Epoch 1  ] ended with valid_loss:   3.83, valid_ppl:  46.07\n",
      "[Epoch 1  ] completed in 18.31 seconds\n",
      "[Epoch 1  ] validation BLEU with greedy search:\n",
      "[Epoch 1  ] BLEU = 11.86 47.7/17.6/8.1/3.8 (BP = 0.932 ratio = 0.934 hyp_len = 12434 ref_len = 13308)\n",
      "\n",
      "[Epoch 2  ] loss:   3.86, perplexity:  47.63\n",
      "[Epoch 2  ] loss:   3.83, perplexity:  45.85\n",
      "[Epoch 2  ] loss:   3.77, perplexity:  43.21\n",
      "[Epoch 2  ] loss:   3.72, perplexity:  41.18\n",
      "[Epoch 2  ] ended with train_loss:   3.70, train_ppl:  40.39\n",
      "[Epoch 2  ] ended with valid_loss:   3.37, valid_ppl:  29.07\n",
      "[Epoch 2  ] completed in 18.92 seconds\n",
      "[Epoch 2  ] validation BLEU with greedy search:\n",
      "[Epoch 2  ] BLEU = 16.10 50.9/21.6/10.9/5.8 (BP = 0.991 ratio = 0.991 hyp_len = 13183 ref_len = 13308)\n",
      "\n",
      "[Epoch 3  ] loss:   3.39, perplexity:  29.61\n",
      "[Epoch 3  ] loss:   3.38, perplexity:  29.26\n",
      "[Epoch 3  ] loss:   3.36, perplexity:  28.66\n",
      "[Epoch 3  ] loss:   3.34, perplexity:  28.10\n",
      "[Epoch 3  ] ended with train_loss:   3.33, train_ppl:  27.81\n",
      "[Epoch 3  ] ended with valid_loss:   3.14, valid_ppl:  23.07\n",
      "[Epoch 3  ] completed in 18.52 seconds\n",
      "[Epoch 3  ] validation BLEU with greedy search:\n",
      "[Epoch 3  ] BLEU = 17.84 52.0/23.6/12.3/6.7 (BP = 1.000 ratio = 1.045 hyp_len = 13902 ref_len = 13308)\n",
      "\n",
      "[Epoch 4  ] loss:   3.13, perplexity:  22.88\n",
      "[Epoch 4  ] loss:   3.11, perplexity:  22.49\n",
      "[Epoch 4  ] loss:   3.11, perplexity:  22.39\n",
      "[Epoch 4  ] loss:   3.10, perplexity:  22.11\n",
      "[Epoch 4  ] ended with train_loss:   3.09, train_ppl:  21.90\n",
      "[Epoch 4  ] ended with valid_loss:   2.98, valid_ppl:  19.60\n",
      "[Epoch 4  ] completed in 19.11 seconds\n",
      "[Epoch 4  ] validation BLEU with greedy search:\n",
      "[Epoch 4  ] BLEU = 20.23 55.2/26.2/14.4/8.0 (BP = 1.000 ratio = 1.002 hyp_len = 13338 ref_len = 13308)\n",
      "\n",
      "[Epoch 5  ] loss:   2.92, perplexity:  18.51\n",
      "[Epoch 5  ] loss:   2.91, perplexity:  18.38\n",
      "[Epoch 5  ] loss:   2.92, perplexity:  18.45\n",
      "[Epoch 5  ] loss:   2.91, perplexity:  18.43\n",
      "[Epoch 5  ] ended with train_loss:   2.91, train_ppl:  18.32\n",
      "[Epoch 5  ] ended with valid_loss:   2.88, valid_ppl:  17.77\n",
      "[Epoch 5  ] completed in 18.34 seconds\n",
      "[Epoch 5  ] validation BLEU with greedy search:\n",
      "[Epoch 5  ] BLEU = 21.74 57.6/28.3/15.8/9.1 (BP = 0.989 ratio = 0.989 hyp_len = 13160 ref_len = 13308)\n",
      "\n",
      " ---> Final test set performance:   2.79, test_ppl:  16.35\n",
      "\n",
      "{'enc_bidirectional': False, 'init_dec': 'max'}\n",
      "  BLEU = 19.78 53.0/25.0/13.9/8.3 (BP = 1.000 ratio = 1.040 hyp_len = 13492 ref_len = 12968)\n",
      "{'enc_bidirectional': False, 'init_dec': 'avg'}\n",
      "  BLEU = 20.05 53.0/25.0/14.2/8.6 (BP = 1.000 ratio = 1.048 hyp_len = 13595 ref_len = 12968)\n",
      "{'enc_bidirectional': True, 'init_dec': 'max'}\n",
      "  BLEU = 22.63 61.9/31.5/18.6/11.4 (BP = 0.893 ratio = 0.898 hyp_len = 11649 ref_len = 12968)\n",
      "{'enc_bidirectional': True, 'init_dec': 'avg'}\n",
      "  BLEU = 22.86 58.0/29.1/16.7/9.9 (BP = 0.994 ratio = 0.994 hyp_len = 12895 ref_len = 12968)\n"
     ]
    }
   ],
   "source": [
    "# add more configurations to here to train other systems\n",
    "# related to the experiments for Q3\n",
    "param_set = [\n",
    "  {'enc_bidirectional': False, 'init_dec': 'max'},\n",
    "  {'enc_bidirectional': False, 'init_dec': 'avg'},\n",
    "  {'enc_bidirectional': True, 'init_dec': 'max'},\n",
    "  {'enc_bidirectional': True, 'init_dec': 'avg'},\n",
    "]\n",
    "\n",
    "bleu_scores = []\n",
    "\n",
    "for params in param_set:\n",
    "  header_msg = f'Training {params}'\n",
    "  print('*' * len(header_msg) + '\\n' + header_msg + '\\n' + '*' * len(header_msg))\n",
    "\n",
    "  # Train for 5 epochs\n",
    "  model = train_encdec_model(n_epochs=5, init_lr=0.0005, **params)\n",
    "\n",
    "  # Translate the test set and get the bleu scores\n",
    "  bleu = model.greedy_search('test', max_len=60)\n",
    "  bleu_scores.append(bleu)\n",
    "  \n",
    "print()\n",
    "\n",
    "for config, score in zip(param_set, bleu_scores):\n",
    "  print(f'{config}\\n  {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsYXRU68SWF7"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "\n",
    "At the end of 5 epochs, the default settings with max-pooled decoder initialisation and uni-directional encoder, should give you a BLEU score of $\\sim$**20** on the test set. Now here are some exercises that you can proceed with:\n",
    "\n",
    "---\n",
    "\n",
    "**Q3: Implement the `avg` initialisation (`get_encoder_average_state()` method) and fill in the table below for uni-directional and bi-directional encoder by training more configurations. What are your conclusions? In the end, which initialisation scheme yields the best BLEU?**\n",
    "\n",
    "**A:** *Example results are given in the below table (these will not be exactly the same for each person).  You should see that bi-directionality seems to add a solid 2-3 BLEU score for both types of initialisation. Note that, we can not conclude by training any model with just 5 epochs and a fixed random seed. In the ideal case, we would have to run it until early-stopping and with several random seeds and compute average and standard deviation of BLEU scores.*\n",
    "\n",
    "| $v$| Unidir.   | Bidir.   |\n",
    "|----|-----------|----------|\n",
    "| max| 19.78      | 22.63     |\n",
    "|avg | 20.05      | 22.86     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTLiSpQPqBv5"
   },
   "source": [
    "## 8. Incorporating `DOT` attention\n",
    "\n",
    "In the following, we derive our attentive NMT model from the `EncDecNMT` and only modify the necessary parts to incorporate the attention mechanism. Specifically, three `Linear` layers are added for decoder's state (query) projection, encoder state (key) projection, and a final projection from encoder's states to output layer dimensionality.\n",
    "\n",
    "---\n",
    "**Q4: Follow the code below and fill two `<TODO>` items in `__init__()` and four more in `compute_decoder_logits()` for the dot attention. (The MLP attention parts are extra exercises that you can come back to, after finishing the other questions.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jUXfLx9Vk-aa"
   },
   "outputs": [],
   "source": [
    "class AttentionNMT(EncDecNMT):\n",
    "  \"\"\"Encoder-decoder NMT with attention.\"\"\"\n",
    "  def __init__(self, **kwargs):\n",
    "    # The internal dimension for the dot product i.e.\n",
    "    # the common dimension that d_t and h_i's should be projected\n",
    "    self.att_dim = kwargs.pop('att_dim')\n",
    "\n",
    "    # The attention type to compute the similarity scores\n",
    "    self.att_type = kwargs.pop('att_type')\n",
    "    assert self.att_type in ('dot', 'mlp'), \"att_type unknown.\"\n",
    "\n",
    "    # Call parent's __init__ with the remaining arguments\n",
    "    super(AttentionNMT, self).__init__(**kwargs)\n",
    "\n",
    "    ############################################\n",
    "    # QUESTION\n",
    "    ############################################\n",
    "    # Add decoder state (query) projection layer\n",
    "    self.ff_q_proj = nn.Linear(self.dec_dim, self.att_dim)\n",
    "\n",
    "    ############################################\n",
    "    # QUESTION\n",
    "    ############################################\n",
    "    # Add encoder states projection layer for similarity computation\n",
    "    ############################################\n",
    "    self.ff_k_proj = nn.Linear(self.enc_out_dim, self.att_dim)\n",
    "\n",
    "    ####################################################\n",
    "    # Adaptor so that the output of attention can be fed\n",
    "    # directly to the `self.bneck` layer\n",
    "    ####################################################\n",
    "    self.ff_enc2bneck = nn.Linear(self.enc_out_dim, self.dec_dim)\n",
    "\n",
    "    if self.att_type == 'mlp':\n",
    "      ###############################################################\n",
    "      # EXTRA QUESTION\n",
    "      # the only parameter you would add is linear layer (no bias)\n",
    "      # representing the `a` vector in the lecture slides.\n",
    "      ###############################################################\n",
    "      #raise RuntimeError('Not implemented yet!')\n",
    "      self.mlp_att = nn.Linear(self.att_dim, 1, bias=False)\n",
    "\n",
    "  def encode(self, x):\n",
    "    # Let's first call the EncDec's encode()\n",
    "    all_hids, mask = super(AttentionNMT, self).encode(x)\n",
    "\n",
    "    # This is to avoid projection of encoder states at each decoding step\n",
    "    # since they can be precomputed at once\n",
    "    self.e_proj = self.ff_k_proj(all_hids)\n",
    "\n",
    "    return all_hids, mask\n",
    "\n",
    "  def compute_decoder_logits(self, dec_hid_state, y):\n",
    "    ###########################################################\n",
    "    # This step is the same as encoder-decoder, we feed the embedding\n",
    "    # and get `d_t` (query for attention) i.e. the hidden state of the decoder\n",
    "    ###########################################################\n",
    "    dec_hid_state = self.dec(self.trg_emb(y), dec_hid_state)\n",
    "\n",
    "    # Below you'll have to do a lot of permute(), t(), squeeze(), unsqueeze()\n",
    "    # operations to make dimensions compatible. Check PyTorch documents\n",
    "    # if you are not familiar with these operations\n",
    "\n",
    "    ###########################################################\n",
    "    # QUESTION\n",
    "    ###########################################################\n",
    "    # Project `dec_hid_state to attention dim with `ff_q_proj` layer\n",
    "    # Expected shape: (batch_size, att_dim, 1)\n",
    "    ###########################################################\n",
    "    proj_q = self.ff_q_proj(dec_hid_state).unsqueeze(-1)\n",
    "\n",
    "    # Permuting the dimensions of already cached `self.e_proj`\n",
    "    # so that the shape becomes: (batch_size, seq_len, att_dim)\n",
    "    proj_e = self.e_proj.permute(1, 0, 2)\n",
    "\n",
    "    ###########################################################\n",
    "    # QUESTION (Dot attention)\n",
    "    ###########################################################\n",
    "    # Now that you have the queries for all the batch (proj_q)\n",
    "    # and encoder states for all source positions in the batch (proj_e)\n",
    "    # you can use `torch.bmm()` to compute all similarity scores at once.\n",
    "    # `bmm` stands for \"Batch matrix multiplication\". If you have two 3D\n",
    "    # tensors where first dimension represents the `batch_size`, `bmm`\n",
    "    # computes the products for each element in the batch.\n",
    "    ##########\n",
    "    # Example:\n",
    "    ##########\n",
    "    # torch.bmm(\"tensor of size B x S x A\" , \"tensor of size B x A x 1\")\n",
    "    #    --> produces a tensor of \"B x S x 1\"\n",
    "    ##########\n",
    "    # Use this to obtain the similarity scores and use squeeze() and t()\n",
    "    # to make it look like (seq_len, batch_size)\n",
    "    if self.att_type == 'dot':\n",
    "      scores = torch.bmm(proj_e, proj_q).squeeze(-1).t()\n",
    "    elif self.att_type == 'mlp':\n",
    "      ###########################################################\n",
    "      # EXTRA QUESTION\n",
    "      ###########################################################\n",
    "      #raise RuntimeError('Not implemented yet!')\n",
    "      x = torch.tanh(proj_e + proj_q.permute(0, 2, 1))\n",
    "      scores = self.mlp_att(x).squeeze(-1).t()\n",
    "\n",
    "    #########################################################\n",
    "    # we fill the padded positions with small numbers so that\n",
    "    # softmax() does not assign probabilities to them.\n",
    "    #########################################################\n",
    "    scores.masked_fill_(self.mask.logical_not(), -1e8)\n",
    "\n",
    "    #############################################\n",
    "    # QUESTION\n",
    "    #############################################\n",
    "    # Use softmax() on `scores` to obtain alpha's / probabilities\n",
    "    # expected shape: (seq_len, batch_size)\n",
    "    alpha = scores.softmax(0)\n",
    "\n",
    "    #############################################\n",
    "    # QUESTION\n",
    "    #############################################\n",
    "    # Weigh the bidirectional encoder states `self.all_hids`\n",
    "    # with `alpha`\n",
    "    # expected shape: (batch_size, self.enc_out_dim)\n",
    "    ctx = (alpha.unsqueeze(-1) * self.all_hids).sum(0)\n",
    "\n",
    "    # Project the computed weighted context to `dec_dim` so that\n",
    "    # the output layer works as espected\n",
    "    # shape: (batch_size, dec_dim)\n",
    "    c_t = self.ff_enc2bneck(ctx)\n",
    "\n",
    "    ##################################################################\n",
    "    # We sum the decoder's state `d_t` and the computed `c_t` together\n",
    "    ##################################################################\n",
    "    logits = self.out(self.bneck(self.drop(c_t + dec_hid_state)))\n",
    "    return logits, dec_hid_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv_3z30aRuCr"
   },
   "source": [
    "## 9. Training the model\n",
    "\n",
    "The following function trains an attentive NMT with the base hyper-parameters that you can override through the keyword arguments. Proceed to the next code block for the actual training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hxv89r81F3Sx"
   },
   "outputs": [],
   "source": [
    "def train_attention_model(n_epochs=5, init_lr=0.0005, **kwargs):\n",
    "  # Set the seed for reproducible results\n",
    "  fix_seed(30494)\n",
    "\n",
    "  base_params = {\n",
    "    'dataset':dataset,\n",
    "    'emb_dim':200,              # word embedding dim\n",
    "    'enc_dim':200,              # hidden layer dim for the encoder\n",
    "    'enc_bidirectional':True,   # True makes the encoder bidirectional\n",
    "    'dec_dim':300,              # hidden layer dim for the decoder\n",
    "    'clip_gradient_norm':1.0,   # gradient clip threshold\n",
    "    'dropout':0.3,              # dropout probability\n",
    "    'tie_weights':True,         # Weight typing for decoder inputs/outputs\n",
    "    'batch_size':64,            # Batch size\n",
    "    'init_dec':'avg',           # Initialize the decoder with max or avg state\n",
    "    'att_dim': 200,             # Dot product's inner dimension\n",
    "    'att_type': 'dot',          # att_type dot/mlp\n",
    "  }\n",
    "\n",
    "  # Override with given arguments\n",
    "  base_params.update(kwargs)\n",
    "\n",
    "  # Create the Pytorch model\n",
    "  model = AttentionNMT(**base_params)\n",
    "\n",
    "  # move to device\n",
    "  model.to(DEVICE)\n",
    "\n",
    "  # Create the optimizer\n",
    "  opt = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "  print(model)\n",
    "\n",
    "  # Returns train, val and test perplexities\n",
    "  model.train_model(opt, n_epochs=n_epochs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbJIeWDYC6kN"
   },
   "source": [
    "Below, you can add different configurations to `param_set` and they will be trained sequentially. At the end, the final model parameters will be used to decode the translations for the test set and BLEU scores will be computed and printed for each configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A36iH_9wHG5I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "Training {'enc_bidirectional': True, 'init_dec': 'avg', 'att_dim': 200, 'att_type': 'dot'}\n",
      "******************************************************************************************\n",
      "AttentionNMT(\n",
      "  (loss): CrossEntropyLoss()\n",
      "  (drop): Dropout(p=0.3, inplace=False)\n",
      "  (src_emb): Embedding(11223, 200, padding_idx=0)\n",
      "  (trg_emb): Embedding(10214, 200, padding_idx=0)\n",
      "  (enc): GRU(200, 200, bidirectional=True)\n",
      "  (dec): GRUCell(200, 300)\n",
      "  (ff_dec_init): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=300, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (bneck): Linear(in_features=300, out_features=200, bias=True)\n",
      "  (out): Linear(in_features=200, out_features=10214, bias=True)\n",
      "  (ff_q_proj): Linear(in_features=300, out_features=200, bias=True)\n",
      "  (ff_k_proj): Linear(in_features=400, out_features=200, bias=True)\n",
      "  (ff_enc2bneck): Linear(in_features=400, out_features=300, bias=True)\n",
      ")\n",
      "# of parameters: 5.67M -- Decoder init: 'avg'\n",
      "[Epoch 1  ] loss:   6.41, perplexity: 608.18\n",
      "[Epoch 1  ] loss:   5.48, perplexity: 240.55\n",
      "[Epoch 1  ] loss:   4.96, perplexity: 142.39\n",
      "[Epoch 1  ] loss:   4.60, perplexity:  99.07\n",
      "[Epoch 1  ] ended with train_loss:   4.44, train_ppl:  85.07\n",
      "[Epoch 1  ] ended with valid_loss:   2.96, valid_ppl:  19.23\n",
      "[Epoch 1  ] completed in 30.21 seconds\n",
      "[Epoch 1  ] validation BLEU with greedy search:\n",
      "[Epoch 1  ] BLEU = 26.92 59.0/34.1/20.7/12.6 (BP = 1.000 ratio = 1.054 hyp_len = 14031 ref_len = 13308)\n",
      "\n",
      "[Epoch 2  ] loss:   3.08, perplexity:  21.65\n",
      "[Epoch 2  ] loss:   3.02, perplexity:  20.53\n",
      "[Epoch 2  ] loss:   2.97, perplexity:  19.53\n",
      "[Epoch 2  ] loss:   2.93, perplexity:  18.69\n",
      "[Epoch 2  ] ended with train_loss:   2.90, train_ppl:  18.24\n",
      "[Epoch 2  ] ended with valid_loss:   2.49, valid_ppl:  12.01\n",
      "[Epoch 2  ] completed in 30.52 seconds\n",
      "[Epoch 2  ] validation BLEU with greedy search:\n",
      "[Epoch 2  ] BLEU = 33.70 64.5/40.9/27.0/18.1 (BP = 1.000 ratio = 1.043 hyp_len = 13877 ref_len = 13308)\n",
      "\n",
      "[Epoch 3  ] loss:   2.56, perplexity:  12.99\n",
      "[Epoch 3  ] loss:   2.56, perplexity:  12.91\n",
      "[Epoch 3  ] loss:   2.53, perplexity:  12.61\n",
      "[Epoch 3  ] loss:   2.52, perplexity:  12.40\n",
      "[Epoch 3  ] ended with train_loss:   2.50, train_ppl:  12.23\n",
      "[Epoch 3  ] ended with valid_loss:   2.29, valid_ppl:   9.83\n",
      "[Epoch 3  ] completed in 30.63 seconds\n",
      "[Epoch 3  ] validation BLEU with greedy search:\n",
      "[Epoch 3  ] BLEU = 37.16 68.5/44.9/30.5/20.8 (BP = 0.994 ratio = 0.994 hyp_len = 13233 ref_len = 13308)\n",
      "\n",
      "[Epoch 4  ] loss:   2.29, perplexity:   9.91\n",
      "[Epoch 4  ] loss:   2.29, perplexity:   9.87\n",
      "[Epoch 4  ] loss:   2.28, perplexity:   9.81\n",
      "[Epoch 4  ] loss:   2.28, perplexity:   9.76\n",
      "[Epoch 4  ] ended with train_loss:   2.28, train_ppl:   9.75\n",
      "[Epoch 4  ] ended with valid_loss:   2.17, valid_ppl:   8.77\n",
      "[Epoch 4  ] completed in 30.45 seconds\n",
      "[Epoch 4  ] validation BLEU with greedy search:\n",
      "[Epoch 4  ] BLEU = 39.34 71.1/48.0/33.7/23.6 (BP = 0.969 ratio = 0.969 hyp_len = 12896 ref_len = 13308)\n",
      "\n",
      "[Epoch 5  ] loss:   2.10, perplexity:   8.14\n",
      "[Epoch 5  ] loss:   2.10, perplexity:   8.20\n",
      "[Epoch 5  ] loss:   2.11, perplexity:   8.21\n",
      "[Epoch 5  ] loss:   2.11, perplexity:   8.23\n",
      "[Epoch 5  ] ended with train_loss:   2.11, train_ppl:   8.26\n",
      "[Epoch 5  ] ended with valid_loss:   2.07, valid_ppl:   7.89\n",
      "[Epoch 5  ] completed in 30.32 seconds\n",
      "[Epoch 5  ] validation BLEU with greedy search:\n",
      "[Epoch 5  ] BLEU = 40.84 70.8/48.4/34.3/24.5 (BP = 0.992 ratio = 0.992 hyp_len = 13196 ref_len = 13308)\n",
      "\n",
      " ---> Final test set performance:   1.97, test_ppl:   7.16\n",
      "******************************************************************************************\n",
      "Training {'enc_bidirectional': True, 'init_dec': 'avg', 'att_dim': 200, 'att_type': 'mlp'}\n",
      "******************************************************************************************\n",
      "AttentionNMT(\n",
      "  (loss): CrossEntropyLoss()\n",
      "  (drop): Dropout(p=0.3, inplace=False)\n",
      "  (src_emb): Embedding(11223, 200, padding_idx=0)\n",
      "  (trg_emb): Embedding(10214, 200, padding_idx=0)\n",
      "  (enc): GRU(200, 200, bidirectional=True)\n",
      "  (dec): GRUCell(200, 300)\n",
      "  (ff_dec_init): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=300, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (bneck): Linear(in_features=300, out_features=200, bias=True)\n",
      "  (out): Linear(in_features=200, out_features=10214, bias=True)\n",
      "  (ff_q_proj): Linear(in_features=300, out_features=200, bias=True)\n",
      "  (ff_k_proj): Linear(in_features=400, out_features=200, bias=True)\n",
      "  (ff_enc2bneck): Linear(in_features=400, out_features=300, bias=True)\n",
      "  (mlp_att): Linear(in_features=200, out_features=1, bias=False)\n",
      ")\n",
      "# of parameters: 5.67M -- Decoder init: 'avg'\n",
      "[Epoch 1  ] loss:   6.52, perplexity: 675.26\n",
      "[Epoch 1  ] loss:   5.69, perplexity: 296.86\n",
      "[Epoch 1  ] loss:   5.19, perplexity: 180.15\n",
      "[Epoch 1  ] loss:   4.85, perplexity: 127.21\n",
      "[Epoch 1  ] ended with train_loss:   4.69, train_ppl: 108.86\n",
      "[Epoch 1  ] ended with valid_loss:   3.21, valid_ppl:  24.86\n",
      "[Epoch 1  ] completed in 32.96 seconds\n",
      "[Epoch 1  ] validation BLEU with greedy search:\n",
      "[Epoch 1  ] BLEU = 22.94 56.2/30.1/17.0/9.7 (BP = 1.000 ratio = 1.056 hyp_len = 14057 ref_len = 13308)\n",
      "\n",
      "[Epoch 2  ] loss:   3.31, perplexity:  27.40\n",
      "[Epoch 2  ] loss:   3.22, perplexity:  24.93\n",
      "[Epoch 2  ] loss:   3.15, perplexity:  23.39\n",
      "[Epoch 2  ] loss:   3.10, perplexity:  22.13\n",
      "[Epoch 2  ] ended with train_loss:   3.07, train_ppl:  21.49\n",
      "[Epoch 2  ] ended with valid_loss:   2.62, valid_ppl:  13.67\n",
      "[Epoch 2  ] completed in 32.68 seconds\n",
      "[Epoch 2  ] validation BLEU with greedy search:\n",
      "[Epoch 2  ] BLEU = 31.85 63.7/39.4/25.3/16.2 (BP = 1.000 ratio = 1.036 hyp_len = 13791 ref_len = 13308)\n",
      "\n",
      "[Epoch 3  ] loss:   2.69, perplexity:  14.80\n",
      "[Epoch 3  ] loss:   2.68, perplexity:  14.55\n",
      "[Epoch 3  ] loss:   2.65, perplexity:  14.19\n",
      "[Epoch 3  ] loss:   2.62, perplexity:  13.75\n",
      "[Epoch 3  ] ended with train_loss:   2.61, train_ppl:  13.61\n",
      "[Epoch 3  ] ended with valid_loss:   2.34, valid_ppl:  10.43\n",
      "[Epoch 3  ] completed in 32.22 seconds\n",
      "[Epoch 3  ] validation BLEU with greedy search:\n",
      "[Epoch 3  ] BLEU = 35.59 67.4/43.4/28.8/19.3 (BP = 0.997 ratio = 0.997 hyp_len = 13269 ref_len = 13308)\n",
      "\n",
      "[Epoch 4  ] loss:   2.40, perplexity:  10.99\n",
      "[Epoch 4  ] loss:   2.37, perplexity:  10.69\n",
      "[Epoch 4  ] loss:   2.36, perplexity:  10.55\n",
      "[Epoch 4  ] loss:   2.34, perplexity:  10.41\n",
      "[Epoch 4  ] ended with train_loss:   2.34, train_ppl:  10.39\n",
      "[Epoch 4  ] ended with valid_loss:   2.20, valid_ppl:   8.99\n",
      "[Epoch 4  ] completed in 32.47 seconds\n",
      "[Epoch 4  ] validation BLEU with greedy search:\n",
      "[Epoch 4  ] BLEU = 36.56 66.3/43.9/29.9/20.5 (BP = 1.000 ratio = 1.051 hyp_len = 13990 ref_len = 13308)\n",
      "\n",
      "[Epoch 5  ] loss:   2.17, perplexity:   8.79\n",
      "[Epoch 5  ] loss:   2.17, perplexity:   8.73\n",
      "[Epoch 5  ] loss:   2.16, perplexity:   8.65\n",
      "[Epoch 5  ] loss:   2.16, perplexity:   8.64\n",
      "[Epoch 5  ] ended with train_loss:   2.16, train_ppl:   8.63\n",
      "[Epoch 5  ] ended with valid_loss:   2.07, valid_ppl:   7.90\n",
      "[Epoch 5  ] completed in 32.85 seconds\n",
      "[Epoch 5  ] validation BLEU with greedy search:\n",
      "[Epoch 5  ] BLEU = 39.66 69.5/47.2/32.9/23.0 (BP = 1.000 ratio = 1.023 hyp_len = 13618 ref_len = 13308)\n",
      "\n",
      " ---> Final test set performance:   1.97, test_ppl:   7.17\n",
      "\n",
      "{'enc_bidirectional': True, 'init_dec': 'avg', 'att_dim': 200, 'att_type': 'dot'}\n",
      "  BLEU = 42.09 71.2/49.1/35.5/25.9 (BP = 0.995 ratio = 0.995 hyp_len = 12898 ref_len = 12968)\n",
      "{'enc_bidirectional': True, 'init_dec': 'avg', 'att_dim': 200, 'att_type': 'mlp'}\n",
      "  BLEU = 40.86 70.1/47.7/34.0/24.5 (BP = 1.000 ratio = 1.020 hyp_len = 13231 ref_len = 12968)\n"
     ]
    }
   ],
   "source": [
    "# add more configurations to here to train other systems\n",
    "param_set = [\n",
    "  {'enc_bidirectional': True, 'init_dec': 'avg', 'att_dim': 200, 'att_type': 'dot'},\n",
    "  {'enc_bidirectional': True, 'init_dec': 'avg', 'att_dim': 200, 'att_type': 'mlp'},\n",
    "]\n",
    "\n",
    "bleu_scores = []\n",
    "\n",
    "for params in param_set:\n",
    "  header_msg = f'Training {params}'\n",
    "  print('*' * len(header_msg) + '\\n' + header_msg + '\\n' + '*' * len(header_msg))\n",
    "\n",
    "  # Train for 5 epochs\n",
    "  model = train_attention_model(n_epochs=5, init_lr=0.0005, **params)\n",
    "\n",
    "  # Translate the test set and get the bleu scores\n",
    "  bleu = model.greedy_search('test', max_len=60)\n",
    "  bleu_scores.append(bleu)\n",
    "\n",
    "print()\n",
    "\n",
    "for config, score in zip(param_set, bleu_scores):\n",
    "  print(f'{config}\\n  {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1-IXRH6R7fq"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "After completing the model and training the provided configuration, you should see a test BLEU of around **42** after 5 epochs! It's almost twice the performance that we observed with the decoder initialisation method ($\\sim$ 20).\n",
    "\n",
    "You can now play with the hyper-parameters to discover a better model in terms of the BLEU score or proceed with the extra questions below!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7m4z7y2F_5Hz"
   },
   "source": [
    "## Extra Questions\n",
    "\n",
    "**Q5:** Modify `EncDecNMT` to add a new initalisation method called `each`. In this mode, instead of initialising the decoder's initial state with the average encoder state, you'll add the average encoder state to each `y_prev` i.e. to each input of the decoder. This way, the same information will be much more accessible throughout decoding, instead of just being used at $t=0$. How does the performance compare to the `avg` method? Do you think initialising the decoder's hidden state is crucial to pass along source sentence representation or are you satisfied with this approach as well?\n",
    "\n",
    "**NOTE:** Make sure that you do no longer initialise your decoder's hidden state with the same information and leave it `None` i.e. a 0-vector initialisation. You can do this by adding a new initialisation method `zero` to your class and implementing the rest accordingly.\n",
    "\n",
    "**ANS:** *You should get approximately the same BLEU score when using this new method. This means that there can be many other ways of passing source side information to the decoder other than the hidden state initialisation.*\n",
    "\n",
    "---\n",
    "\n",
    "**Q6: (Attentive NMT)** Experiment and try to come up with a better hyper-parameters settings that surpasses the default setting in terms of test BLEU. For example, you can try increasing the number of layers in the encoder to see what happens.\n",
    "\n",
    "**ANS:** *You are likely to see a higher test BLEU score with a stacked 2-layer GRU encoder*.\n",
    "\n",
    "---\n",
    "\n",
    "**Q7: (Attentive NMT)** Fill in the missing parts to implement the MLP attention. Compare the performance to `dot` attention by keeping all other hyper-parameters the same.\n",
    "\n",
    "**ANS:** Although MLP attention gives a slightly lower BLEU score of ~40.6 after 5 epochs, no conclusions should be drawn unless models are trained until completion or early-stopping."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab04_mt_solutions.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.16 64-bit ('py38_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff27035c8dc0a26468b79942def09685664b2e815f4bca7e9395dcaceb48c986"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
