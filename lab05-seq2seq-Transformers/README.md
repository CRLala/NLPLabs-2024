Lab05 Structure:

- Part 1: transaltion using Transformers. You will be asked to implement the main components of a seq2seq model for translation, MarianMT.
- Part 2: summarization using Transformers. This focuses on using the Huggingface APIs and builtin functionality for another seq2sq task. This hopefully should not take too long after completing part 1.
- Part 3: a tutorial on decoding strategies using GPT-2. This will ask you to re-implement several of the Huggingface generative decoding functions.
